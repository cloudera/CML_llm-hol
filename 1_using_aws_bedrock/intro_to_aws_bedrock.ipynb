{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29837cb6-9eed-490f-a1b9-729c1171c565",
   "metadata": {},
   "source": [
    "# Introduction to Amazon Bedrock Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e55726b-ac9b-4033-889c-2a90955dff81",
   "metadata": {},
   "source": [
    "## Set AWS access credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba4a7ca-abd9-4cc6-b431-0373bb18e0f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5d988a-fab1-4c16-ba2a-696b66aaf363",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58bc9967-bc2d-4ef5-a50d-9c8a27ded0d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Optional\n",
    "import boto3\n",
    "from botocore.config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9fd5fa-46f1-460a-8a54-646de855cc78",
   "metadata": {},
   "source": [
    "## Set up Amazon Bedrock Client with boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a3983ef-b4a1-4833-b046-2a252353159f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bedrock_client(\n",
    "    assumed_role: Optional[str] = None,\n",
    "    endpoint_url: Optional[str] = None,\n",
    "    region: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"Create a boto3 client for Amazon Bedrock, with optional configuration overrides\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    assumed_role :\n",
    "        Optional ARN of an AWS IAM role to assume for calling the Bedrock service. If not\n",
    "        specified, the current active credentials will be used.\n",
    "    endpoint_url :\n",
    "        Optional override for the Bedrock service API Endpoint. If setting this, it should usually\n",
    "        include the protocol i.e. \"https://...\"\n",
    "    region :\n",
    "        Optional name of the AWS Region in which the service should be called (e.g. \"us-east-1\").\n",
    "        If not specified, AWS_REGION or AWS_DEFAULT_REGION environment variable will be used.\n",
    "    \"\"\"\n",
    "    if region is None:\n",
    "        target_region = os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\"))\n",
    "    else:\n",
    "        target_region = region\n",
    "\n",
    "    print(f\"Create new client\\n  Using region: {target_region}\")\n",
    "    session_kwargs = {\"region_name\": target_region}\n",
    "    client_kwargs = {**session_kwargs}\n",
    "\n",
    "    profile_name = os.environ.get(\"AWS_PROFILE\")\n",
    "    if profile_name:\n",
    "        print(f\"  Using profile: {profile_name}\")\n",
    "        session_kwargs[\"profile_name\"] = profile_name\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=target_region,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "    session = boto3.Session(**session_kwargs)\n",
    "\n",
    "    if assumed_role:\n",
    "        print(f\"  Using role: {assumed_role}\", end='')\n",
    "        sts = session.client(\"sts\")\n",
    "        response = sts.assume_role(\n",
    "            RoleArn=str(assumed_role),\n",
    "            RoleSessionName=\"langchain-llm-1\"\n",
    "        )\n",
    "        print(\" ... successful!\")\n",
    "        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n",
    "        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n",
    "        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n",
    "\n",
    "    if endpoint_url:\n",
    "        client_kwargs[\"endpoint_url\"] = endpoint_url\n",
    "\n",
    "    bedrock_client = session.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        config=retry_config,\n",
    "        **client_kwargs\n",
    "    )\n",
    "\n",
    "    print(\"boto3 Bedrock client successfully created!\")\n",
    "    print(bedrock_client._endpoint)\n",
    "    return bedrock_client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8444b23e-f063-4923-b12e-54e453529ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initializing the bedrock client using AWS credentials\n",
    "# If you are using a special Assumed role or custom endpoint url, see get_bedrock_client\n",
    "boto3_bedrock = get_bedrock_client(\n",
    "      region=os.environ.get(\"AWS_DEFAULT_REGION\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638762a2-0257-4a91-b016-502d0361859c",
   "metadata": {},
   "source": [
    "# [TODO] Below may need to be adjusted for Q&A "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3118c5-e310-4748-96d8-61f2016deab8",
   "metadata": {},
   "source": [
    "## Set desired instruction\n",
    "The bedrock models shown in this notebook (Amazon's Titan and Anthropic's Claude) are both general instruction-following text generation models. Meaning we can provide some instructions and input text to generate a response that will follow the instructions provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a09516a0-a82d-4101-a33d-0e101371bcce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction_text = \"Please provide a summary of the following text. Do not add any information that is not mentioned in the text below.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a9f24-193e-4afa-b203-f0d6e4a7bcd6",
   "metadata": {},
   "source": [
    "## Set desired input text\n",
    "This is the input text that we want to be summarized. The length of this text plus any included instructions must fit within the context window size of the selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06fb50d0-4710-485c-8cc8-94503d868e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_text = '''Machine learning has become one of the most critical capabilities for modern businesses to grow and stay competitive today. From automating internal processes to optimizing the design, creation, and marketing processes behind virtually every product consumed, ML models have permeated almost every aspect of our work and personal lives.\n",
    "\n",
    "ML development is iterative and complex, made even harder because most ML tools arenâ€™t built for the entire machine learning lifecycle. Cloudera Machine Learning on Cloudera Data Platform accelerates time-to-value by enabling data scientists to collaborate in a single unified platform that is all inclusive for powering any AI use case. Purpose-built for agile experimentation and production ML workflows, Cloudera Machine Learning manages everything from data preparation to MLOps, to predictive reporting. Solve mission critical ML challenges along the entire lifecycle with greater speed and agility to discover opportunities which can mean the difference for your business.\n",
    "\n",
    "Each ML workspace enables teams of data scientists to develop, test, train, and ultimately deploy machine learning models for building predictive applications all on the data under management within the enterprise data cloud. ML workspaces support fully-containerized execution of Python, R, Scala, and Spark workloads through flexible and extensible engines.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914bc03a-5d6d-4cc5-9eb5-3ded6a724430",
   "metadata": {},
   "source": [
    "## Creating Prompt for Titan model\n",
    "The format of this engineered prompt is specific to the Titan model with special tags lilke <text></text>. See AWS Bedrock documentation for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7421cd3e-bb99-4792-ade0-71edac20a15d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_prompt = instruction_text + \"\"\"\\n<text>\"\"\" + input_text + \"\"\"</text>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a5494-4c00-4f8e-b5a3-22d7b1fd4a2b",
   "metadata": {},
   "source": [
    "## Creating API request for Titan model\n",
    "The parameters and format required for this API request is specific to the Titan model, see AWS Bedrock documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d66c113-5b2b-4085-a386-783a09c8a4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "body = json.dumps({\"inputText\": full_prompt, \n",
    "                   \"textGenerationConfig\":{\n",
    "                       \"maxTokenCount\":4096,\n",
    "                       \"stopSequences\":[],\n",
    "                       \"temperature\":0.60,\n",
    "                       \"topP\":1}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f15aa4-80df-4b23-83f3-519a493c6b32",
   "metadata": {},
   "source": [
    "## Titan Inference API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d444a471-6c26-4d52-b352-d76c6cd8964b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelId = 'amazon.titan-tg1-large'\n",
    "response = boto3_bedrock.invoke_model(body=body, modelId=modelId, accept='application/json', contentType='application/json')\n",
    "response_body = json.loads(response.get('body').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6438ef6-932b-41f5-843d-bf7c04a7b019",
   "metadata": {},
   "source": [
    "The response body is specific to the Titan Model API, see AWS Bedrock documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0bbc890-b0bb-45bf-b856-60e5bad958af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modern companies need machine learning to develop and compete, and Cloudera Machine Learning on Cloudera Data Platform speeds up time-to-value by enabling data scientists to work together in a single, integrated environment. It handles everything from data preparation to MLOps, to predictive reporting, and enables fully-containerized execution of Python, R, Scala, and Spark workloads.\n"
     ]
    }
   ],
   "source": [
    "result = response_body.get('results')[0].get('outputText')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299a9a6-bec2-425d-92ce-a31a7ea4e23c",
   "metadata": {},
   "source": [
    "## Creating Prompt for Claude model\n",
    "The format of this engineered prompt is specific to the Claude model with special tags lilke <text></text>. See AWS Bedrock documentation for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "278c9aaf-b566-49e3-b9c6-a322ed0590af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_prompt = \"\"\"Human: \"\"\" + instruction_text + \"\"\"\\n<text>\"\"\" + input_text + \"\"\"</text>\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec289c20-61ca-486b-82f8-f405233073df",
   "metadata": {},
   "source": [
    "## Creating API request for Claude model\n",
    "The parameters and format required for this API request is specific to the Claude model, see AWS Bedrock documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d72a96e-14ab-4b8f-907f-d797241c35e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "body = json.dumps({\"prompt\": full_prompt,\n",
    "             \"max_tokens_to_sample\":4096,\n",
    "             \"temperature\":0.6,\n",
    "             \"top_k\":250,\n",
    "             \"top_p\":1.0,\n",
    "             \"stop_sequences\":[]\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28be09e-2383-45e0-b2b9-31ae0818c063",
   "metadata": {},
   "source": [
    "## Claude Inference API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38725f73-488a-486b-a757-fd084871961a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelId = 'anthropic.claude-v2'\n",
    "response = boto3_bedrock.invoke_model(body=body, modelId=modelId, accept='application/json', contentType='application/json')\n",
    "response_body = json.loads(response.get('body').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbc3707-383f-4365-a28d-7cb464820364",
   "metadata": {},
   "source": [
    "The response body is specific to the Claude Model API, see AWS Bedrock documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74100659-2731-490e-8572-c94801ad0e14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a summary of the key points from the text:\n",
      "\n",
      "- Machine learning has become critical for modern businesses to stay competitive by automating processes and optimizing products. \n",
      "\n",
      "- ML development is complex and iterative. Most ML tools aren't built for the entire lifecycle. \n",
      "\n",
      "- Cloudera Machine Learning accelerates time-to-value by enabling collaboration on a unified platform for any AI use case. It manages data preparation, MLOps, and reporting.\n",
      "\n",
      "- ML workspaces in Cloudera let data science teams develop, test, train, and deploy models to build predictive apps using Python, R, Scala, Spark, etc.\n"
     ]
    }
   ],
   "source": [
    "result = response_body.get('completion')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5490730-1f26-4478-8a31-6c2ae0f1b09f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
