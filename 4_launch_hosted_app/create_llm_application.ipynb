{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Your App!\n",
    "#### Use this Notebook after you have Populated Pinecone with the relevant vectors for your application and you are now ready to deploy your app in CML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Import variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cmlapi\n",
    "import random\n",
    "import string\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Get CML API Client and list the available Runtimes\n",
    "This code connects to your Cloudera Machine Learning (CML) environment, retrieves a list of available Python 3.10 runtimes with Nvidia GPU support and JupyterLab as the editor, prints the list, and then selects and stores the image identifier of the second runtime in the list. It also sets an environment variable APP_IMAGE_ML_RUNTIME with this image identifier for future use in launching jobs within the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'next_page_token': '',\n",
      " 'runtimes': [{'description': 'Python runtime with CUDA libraries provided by '\n",
      "                              'Cloudera',\n",
      "               'edition': 'Nvidia GPU',\n",
      "               'editor': 'JupyterLab',\n",
      "               'full_version': '2023.08.1-b6',\n",
      "               'image_identifier': 'docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.10-cuda:2023.08.1-b6',\n",
      "               'kernel': 'Python 3.10',\n",
      "               'status': 'ENABLED'},\n",
      "              {'description': 'Python runtime with CUDA libraries provided by '\n",
      "                              'Cloudera',\n",
      "               'edition': 'Nvidia GPU',\n",
      "               'editor': 'JupyterLab',\n",
      "               'full_version': '2023.08.2-b8',\n",
      "               'image_identifier': 'docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.10-cuda:2023.08.2-b8',\n",
      "               'kernel': 'Python 3.10',\n",
      "               'status': 'ENABLED'}]}\n",
      "{'description': 'Python runtime with CUDA libraries provided by Cloudera',\n",
      " 'edition': 'Nvidia GPU',\n",
      " 'editor': 'JupyterLab',\n",
      " 'full_version': '2023.08.2-b8',\n",
      " 'image_identifier': 'docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.10-cuda:2023.08.2-b8',\n",
      " 'kernel': 'Python 3.10',\n",
      " 'status': 'ENABLED'}\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.10-cuda:2023.08.2-b8\n"
     ]
    }
   ],
   "source": [
    "client = cmlapi.default_client(url=os.getenv(\"CDSW_API_URL\").replace(\"/api/v1\", \"\"), cml_api_key=os.getenv(\"CDSW_APIV2_KEY\"))\n",
    "available_runtimes = client.list_runtimes(search_filter=json.dumps({\n",
    "    \"kernel\": \"Python 3.10\",\n",
    "    \"edition\": \"Nvidia GPU\",\n",
    "    \"editor\": \"JupyterLab\"\n",
    "}))\n",
    "print(available_runtimes)\n",
    "\n",
    "## Set available runtimes to the latest runtime in the environment (iterator is the number that begins with 0 and advances sequentially)\n",
    "## The JOB_IMAGE_ML_RUNTIME variable stores the ML Runtime which will be used to launch the job\n",
    "print(available_runtimes.runtimes[1])\n",
    "print(available_runtimes.runtimes[1].image_identifier)\n",
    "APP_IMAGE_ML_RUNTIME = available_runtimes.runtimes[1].image_identifier\n",
    "\n",
    "## Store the ML Runtime for any future jobs in an environment variable so we don't have to do this step again\n",
    "os.environ['APP_IMAGE_ML_RUNTIME'] = APP_IMAGE_ML_RUNTIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Get the current working project\n",
    "Here we get the current project from the environment variable \"CDSW Project ID\" and print its metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': datetime.datetime(2023, 12, 11, 21, 45, 34, 844743, tzinfo=tzlocal()),\n",
      " 'creation_status': 'success',\n",
      " 'creator': {'email': 'ktalbert@cloudera.com',\n",
      "             'name': 'Kevin Talbert',\n",
      "             'username': 'ktalbert'},\n",
      " 'default_engine_type': 'ml_runtime',\n",
      " 'description': '',\n",
      " 'environment': '{\"CDSW_APP_POLLING_ENDPOINT\":\"/\",\"PROJECT_OWNER\":\"ktalbert\"}',\n",
      " 'ephemeral_storage_limit': 10,\n",
      " 'ephemeral_storage_request': 0,\n",
      " 'id': 'ven5-648f-q47e-b3n5',\n",
      " 'name': 'CML-LLM-HOL-Workshop',\n",
      " 'owner': {'email': 'ktalbert@cloudera.com',\n",
      "           'name': 'Kevin Talbert',\n",
      "           'username': 'ktalbert'},\n",
      " 'permissions': {'admin': True,\n",
      "                 'business_user': True,\n",
      "                 'inherit': False,\n",
      "                 'operator': True,\n",
      "                 'read': True,\n",
      "                 'write': True},\n",
      " 'shared_memory_limit': 0,\n",
      " 'updated_at': datetime.datetime(2023, 12, 12, 2, 6, 51, 228788, tzinfo=tzlocal()),\n",
      " 'visibility': 'private'}\n"
     ]
    }
   ],
   "source": [
    "project = client.get_project(project_id=os.getenv(\"CDSW_PROJECT_ID\"))\n",
    "print(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Create and Run Application for Hosted LLM Application\n",
    "This code creates a Cloudera Machine Learning (CML) application with the name \"CML LLM Gradio Interface\" and a description, associates it with a specific project (project.id), assigns it a subdomain, specifies Python 3 as the kernel, and provides a script path for the application. It also sets resource specifications for CPU and memory and assigns the runtime identifier obtained from the environment variable APP_IMAGE_ML_RUNTIME. Finally, it creates the application within the specified project using the client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "application_request = cmlapi.CreateApplicationRequest(\n",
    "     name = \"CML LLM Gradio Interface\",\n",
    "     description = \"Hosted interface for the CML LLM Gradio UI\",\n",
    "     project_id = project.id,\n",
    "     subdomain = \"cml-llm-interface\",\n",
    "     kernel = \"python3\",\n",
    "     script = \"4_launch_hosted_app/frontend_app.py\",\n",
    "     cpu = 2,\n",
    "     memory = 8,\n",
    "     runtime_identifier = os.getenv('APP_IMAGE_ML_RUNTIME')\n",
    ")\n",
    "\n",
    "app = client.create_application(\n",
    "     project_id = project.id,\n",
    "     body = application_request\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
